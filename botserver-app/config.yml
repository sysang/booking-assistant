# The config recipe.
# https://rasa.com/docs/rasa/model-configuration/
# recipe: default.v1

# Configuration for Rasa NLU.
# https://rasa.com/docs/rasa/nlu/components/
language: en

pipeline:
# No configuration for the NLU pipeline was provided. The following default pipeline was used to train your model.
# If you'd like to customize it, uncomment and adjust the pipeline.
# See https://rasa.com/docs/rasa/tuning-your-model for more information.
  - name: WhitespaceTokenizer
    intent_tokenization_flag: True
    intent_split_symbol: "+"
  - name: RegexFeaturizer
  - name: LexicalSyntacticFeaturizer
  - name: CountVectorsFeaturizer
  - name: CountVectorsFeaturizer
    analyzer: char_wb
    min_ngram: 1
    max_ngram: 4
  - name: DIETClassifier
    epochs: 50
    constrain_similarities: true
    batch_size: [64, 256]
  - name: EntitySynonymMapper
  - name: ResponseSelector
    epochs: 100
    constrain_similarities: true
  - name: FallbackClassifier
    threshold: 0.3
    ambiguity_threshold: 0.1

# Configuration for Rasa Core.
# https://rasa.com/docs/rasa/core/policies/
policies:
# No configuration for policies was provided. The following default policies were used to train your model.
# If you'd like to customize them, uncomment and adjust the policies.
# See https://rasa.com/docs/rasa/policies for more information.
  # - name: MemoizationPolicy
  - name: RulePolicy
    core_fallback_threshold: 0.12
    core_fallback_action_name: "custom_action_fallback"
    enable_fallback_prediction: True
    restrict_rules: true
    check_for_contradictions: true
  - name: UnexpecTEDIntentPolicy
    tolerance: 0.15
    max_history: 10
    learning_rate: 0.001
    epochs: 71
    constrain_similarities: true
    model_confidence: linear_norm  # softmax | linear_norm
    batch_size: [64, 256]
    dense_dimension:
      text: 128
      intent: 20
      action_name: 20
      label_intent: 20
      entities: 20
      slots: 48
      active_loop: 20
    encoding_dimension: 32
    transformer_size:
      text: 64
      dialogue: 64
    number_of_transformer_layers:
      text: 4
      dialogue: 4
    number_of_attention_heads: 8
  - name: TEDPolicy
    max_history: 10
    learning_rate: 0.001
    epochs: 17
    constrain_similarities: true
    model_confidence: linear_norm
    batch_size: [64, 256]
    dense_dimension:
      text: 128
      intent: 20
      action_name: 20
      label_intent: 20
      entities: 20
      slots: 48
      active_loop: 20
    encoding_dimension: 32
    transformer_size:
      text: 64
      dialogue: 64
      action_text: 64
      label_action_text: 64
    number_of_transformer_layers:
      text: 4
      dialogue: 4
      action_text: 3
      label_action_text: 3
    number_of_attention_heads: 8
